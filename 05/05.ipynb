{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "train_path = glob.glob('./input/train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('./input/train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path, train_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    transforms.RandomRotation(10),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=True, \n",
    "    num_workers=10,\n",
    ")\n",
    "\n",
    "val_path = glob.glob('./input/val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('./input/val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # \n",
    "        self.fc1 = nn.Linear(32*3*7, 11)\n",
    "        self.fc2 = nn.Linear(32*3*7, 11)\n",
    "        self.fc3 = nn.Linear(32*3*7, 11)\n",
    "        self.fc4 = nn.Linear(32*3*7, 11)\n",
    "        self.fc5 = nn.Linear(32*3*7, 11)\n",
    "        self.fc6 = nn.Linear(32*3*7, 11)\n",
    "    \n",
    "    def forward(self, img):        \n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        return c1, c2, c3, c4, c5, c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        c0, c1, c2, c3, c4 = model(input)\n",
    "        loss = criterion(c0, target[:, 0]) + \\\n",
    "                criterion(c1, target[:, 1]) + \\\n",
    "                criterion(c2, target[:, 2]) + \\\n",
    "                criterion(c3, target[:, 3]) + \\\n",
    "                criterion(c4, target[:, 4])\n",
    "        \n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "            \n",
    "            c0, c1, c2, c3, c4 = model(input)\n",
    "            loss = criterion(c0, target[:, 0]) + \\\n",
    "                    criterion(c1, target[:, 1]) + \\\n",
    "                    criterion(c2, target[:, 2]) + \\\n",
    "                    criterion(c3, target[:, 3]) + \\\n",
    "                    criterion(c4, target[:, 4])\n",
    "            # loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                c0, c1, c2, c3, c4, c5 = model(data[0])\n",
    "                output = np.concatenate([c0.data.numpy(), c1.data.numpy(),\n",
    "                   c2.data.numpy(), c3.data.numpy(),\n",
    "                   c4.data.numpy(), c5.data.numpy()], axis=1)\n",
    "                test_pred.append(output)\n",
    "        \n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    \n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 3.5916794080734253 \t Val loss: 3.469150007247925\n",
      "Val Acc 0.3502\n",
      "Epoch: 1, Train loss: 2.2533105433781944 \t Val loss: 2.9302007422447205\n",
      "Val Acc 0.444\n",
      "Epoch: 2, Train loss: 1.89755801320076 \t Val loss: 2.8217370276451113\n",
      "Val Acc 0.4626\n",
      "Epoch: 3, Train loss: 1.681998073498408 \t Val loss: 2.8393633995056153\n",
      "Val Acc 0.4879\n",
      "Epoch: 4, Train loss: 1.5414364697138467 \t Val loss: 2.6904051160812377\n",
      "Val Acc 0.5046\n",
      "Epoch: 5, Train loss: 1.4113399815162022 \t Val loss: 2.5063601398468016\n",
      "Val Acc 0.5299\n",
      "Epoch: 6, Train loss: 1.3268715961376827 \t Val loss: 2.5053544607162475\n",
      "Val Acc 0.5302\n",
      "Epoch: 7, Train loss: 1.2392342685858408 \t Val loss: 2.5663475694656372\n",
      "Val Acc 0.5313\n",
      "Epoch: 8, Train loss: 1.1620981956720353 \t Val loss: 2.597924663066864\n",
      "Val Acc 0.5272\n",
      "Epoch: 9, Train loss: 1.121318035006523 \t Val loss: 2.4031156899929047\n",
      "Val Acc 0.5626\n",
      "Epoch: 10, Train loss: 1.0432440340916316 \t Val loss: 2.3946665320396425\n",
      "Val Acc 0.5684\n",
      "Epoch: 11, Train loss: 1.0026648642619451 \t Val loss: 2.4506330962181093\n",
      "Val Acc 0.5532\n",
      "Epoch: 12, Train loss: 0.9510614156325659 \t Val loss: 2.652621199131012\n",
      "Val Acc 0.5316\n",
      "Epoch: 13, Train loss: 0.8854409048755963 \t Val loss: 2.5649312357902527\n",
      "Val Acc 0.5518\n",
      "Epoch: 14, Train loss: 0.8249279318650563 \t Val loss: 2.4992979714870454\n",
      "Val Acc 0.569\n",
      "Epoch: 15, Train loss: 0.7858790398637454 \t Val loss: 2.5736259837150572\n",
      "Val Acc 0.5618\n",
      "Epoch: 16, Train loss: 0.7501991641521454 \t Val loss: 2.778320771455765\n",
      "Val Acc 0.5537\n",
      "Epoch: 17, Train loss: 0.7231378891269366 \t Val loss: 2.637971424818039\n",
      "Val Acc 0.5599\n",
      "Epoch: 18, Train loss: 0.66217179864645 \t Val loss: 2.7684483141899108\n",
      "Val Acc 0.5571\n",
      "Epoch: 19, Train loss: 0.625422065714995 \t Val loss: 2.7118354322910307\n",
      "Val Acc 0.5769\n",
      "Epoch: 20, Train loss: 0.590535372833411 \t Val loss: 3.2600453991889955\n",
      "Val Acc 0.5389\n",
      "Epoch: 21, Train loss: 0.5485458578467369 \t Val loss: 2.745047454357147\n",
      "Val Acc 0.5734\n",
      "Epoch: 22, Train loss: 0.520045847594738 \t Val loss: 3.0227313826084137\n",
      "Val Acc 0.5668\n",
      "Epoch: 23, Train loss: 0.4734420661777258 \t Val loss: 3.0737359676361082\n",
      "Val Acc 0.5633\n",
      "Epoch: 24, Train loss: 0.4549937278529008 \t Val loss: 3.1458393630981445\n",
      "Val Acc 0.5626\n",
      "Epoch: 25, Train loss: 0.4295532526274522 \t Val loss: 3.33315570795536\n",
      "Val Acc 0.5589\n",
      "Epoch: 26, Train loss: 0.4030587601860364 \t Val loss: 3.3417185983657838\n",
      "Val Acc 0.5557\n",
      "Epoch: 27, Train loss: 0.38127864376952253 \t Val loss: 3.4158888759613038\n",
      "Val Acc 0.5645\n",
      "Epoch: 28, Train loss: 0.3658151648491621 \t Val loss: 3.4181604249477386\n",
      "Val Acc 0.5561\n",
      "Epoch: 29, Train loss: 0.3574470471491416 \t Val loss: 3.502527732372284\n",
      "Val Acc 0.5512\n",
      "Epoch: 30, Train loss: 0.32661300455530484 \t Val loss: 3.692664876937866\n",
      "Val Acc 0.5525\n",
      "Epoch: 31, Train loss: 0.3151220947752396 \t Val loss: 3.559754369020462\n",
      "Val Acc 0.559\n",
      "Epoch: 32, Train loss: 0.29293260678152244 \t Val loss: 3.4571798720359803\n",
      "Val Acc 0.5574\n",
      "Epoch: 33, Train loss: 0.2936108505949378 \t Val loss: 3.8870652294158936\n",
      "Val Acc 0.5478\n",
      "Epoch: 34, Train loss: 0.2792430400302013 \t Val loss: 3.799142812013626\n",
      "Val Acc 0.5482\n",
      "Epoch: 35, Train loss: 0.2565100996990999 \t Val loss: 4.230583559513092\n",
      "Val Acc 0.5422\n",
      "Epoch: 36, Train loss: 0.24662684301038584 \t Val loss: 3.974564911365509\n",
      "Val Acc 0.5546\n",
      "Epoch: 37, Train loss: 0.24446895767282695 \t Val loss: 3.703915699720383\n",
      "Val Acc 0.5595\n",
      "Epoch: 38, Train loss: 0.24247888885686794 \t Val loss: 4.101466446876526\n",
      "Val Acc 0.5678\n",
      "Epoch: 39, Train loss: 0.2387009177704652 \t Val loss: 4.20621438074112\n",
      "Val Acc 0.5502\n",
      "Epoch: 40, Train loss: 0.22340995943918823 \t Val loss: 4.279622220993042\n",
      "Val Acc 0.5416\n",
      "Epoch: 41, Train loss: 0.21830295071254174 \t Val loss: 3.8201751697063444\n",
      "Val Acc 0.5549\n",
      "Epoch: 42, Train loss: 0.20698721767713626 \t Val loss: 3.9902712807655334\n",
      "Val Acc 0.5635\n",
      "Epoch: 43, Train loss: 0.2071385404864947 \t Val loss: 4.288825918197632\n",
      "Val Acc 0.5451\n",
      "Epoch: 44, Train loss: 0.19464707981795074 \t Val loss: 4.237582149982452\n",
      "Val Acc 0.5568\n",
      "Epoch: 45, Train loss: 0.1844821801086267 \t Val loss: 4.26978265953064\n",
      "Val Acc 0.5551\n",
      "Epoch: 46, Train loss: 0.18530221053088705 \t Val loss: 4.203904342412948\n",
      "Val Acc 0.5466\n",
      "Epoch: 47, Train loss: 0.1845099629163742 \t Val loss: 4.449378335475922\n",
      "Val Acc 0.5522\n",
      "Epoch: 48, Train loss: 0.16793036961182953 \t Val loss: 4.3624784722328185\n",
      "Val Acc 0.5497\n",
      "Epoch: 49, Train loss: 0.1761332400130729 \t Val loss: 4.350483274936676\n",
      "Val Acc 0.5657\n"
     ]
    }
   ],
   "source": [
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "best_loss = 1000.0\n",
    "\n",
    "use_cuda = True\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    val_loss = validate(val_loader, model, criterion)\n",
    "    \n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict(val_loader, model, 1)\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "        val_predict_label[:, 44:55].argmax(1),\n",
    "    ]).T\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        val_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "    \n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "    \n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "    print('Val Acc', val_char_acc)\n",
    "    # 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        # print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "        torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "test_path = glob.glob('./input/test_a/*.png')\n",
    "test_path.sort()\n",
    "test_label = [[1]] * len(test_path)\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=10,\n",
    ")\n",
    "\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "\n",
    "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1),\n",
    "    test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1),\n",
    "    test_predict_label[:, 33:44].argmax(1),\n",
    "    test_predict_label[:, 44:55].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "    \n",
    "import pandas as pd\n",
    "df_submit = pd.read_csv('./input/test_A_sample_submit.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('renset18.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
